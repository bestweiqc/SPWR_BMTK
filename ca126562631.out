ModuleCmd_Load.c(213):ERROR:105: Unable to locate a modulefile for 'cuda'
Running model at Mon Sep  9 14:46:57 PDT 2019
numprocs=100
NEURON -- VERSION 7.6.5 master (f3dad62b) 2019-01-11
Duke, Yale, and the BlueBrain Project -- Copyright 1984-2018
See http://neuron.yale.edu/neuron/credits

--------------------------------------------------------------------------
An MPI process has executed an operation involving a call to the
"fork()" system call to create a child process.  Open MPI is currently
operating in a condition that could result in memory corruption or
other system errors; your MPI job may hang, crash, or produce silent
data corruption.  The use of fork() (or system() or other calls that
create child processes) is strongly discouraged.  

The process that invoked fork was:

  Local host:          comet-18-44 (PID 480)
  MPI_COMM_WORLD rank: 35

If you are *absolutely sure* that your application will successfully
and correctly survive a call to fork(), you may disable this warning
by setting the mpi_warn_on_fork MCA parameter to 0.
--------------------------------------------------------------------------
2019-09-09 14:47:04,335 [INFO] Created log file
2019-09-09 14:47:04,336 [INFO] Running NEURON with mpi (100 cores).
Additional mechanisms from files
 modfiles/CaDynamics.mod modfiles/Ca_HVA.mod modfiles/Ca_LVA.mod modfiles/Ih.mod modfiles/Im.mod modfiles/Im_v2.mod modfiles/Kd.mod modfiles/K_P.mod modfiles/K_T.mod modfiles/Kv2like.mod modfiles/Kv3_1.mod modfiles/Nap.mod modfiles/NaTa.mod modfiles/NaTs.mod modfiles/NaV.mod modfiles/SK.mod modfiles/vecevent.mod
2019-09-09 14:47:04,962 [INFO] Building cells.
2019-09-09 14:47:05,260 [INFO] Building recurrent connections
2019-09-09 14:47:05,262 [WARNING] Was unable to run h5py in parallel (mpi) mode. Saving of membrane variable(s) may slow down.
2019-09-09 14:47:05,352 [INFO] Running simulation for 1000.000 ms with the time step 0.100 ms
2019-09-09 14:47:05,352 [INFO] Starting timestep: 0 at t_sim: 0.000 ms
2019-09-09 14:47:05,352 [INFO] Block save every 5000 steps
2019-09-09 14:47:05,608 [INFO]     step:5000 t_sim:500.00 ms
2019-09-09 14:47:05,832 [INFO]     step:10000 t_sim:1000.00 ms
2019-09-09 14:47:06,436 [INFO] Simulation completed in 1.085 seconds 
--------------------------------------------------------------------------
mpirun has exited due to process rank 36 with PID 0 on
node comet-18-44 exiting improperly. There are three reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

3. this process called "MPI_Abort" or "orte_abort" and the mca parameter
orte_create_session_dirs is set to false. In this case, the run-time cannot
detect that the abort call was an abnormal termination. Hence, the only
error message you will receive is this one.

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).

You can avoid this message by specifying -quiet on the mpirun command line.

--------------------------------------------------------------------------
[comet-18-12.sdsc.edu:32257] 99 more processes have sent help message help-mpi-runtime.txt / mpi_init:warn-fork
[comet-18-12.sdsc.edu:32257] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
Done running model at Mon Sep  9 14:47:06 PDT 2019
